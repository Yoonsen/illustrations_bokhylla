{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "biblio = \"/home/larj/urn-biblio-mods.db\"\n",
    "filelist = \"/home/larj/notebooks/filelist.db\"\n",
    "nbdigital = \"/disk4/\"\n",
    "ramdisk = '/ram_work' \n",
    "import json\n",
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "from multiprocessing import Pool\n",
    "import ipyparallel as ipp\n",
    "import sqlite3\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query(db, query, param=\"\"):\n",
    "    with sqlite3.connect(db) as con:\n",
    "        cur = con.cursor()\n",
    "        try:\n",
    "            res = cur.execute(query, param).fetchall()\n",
    "        except:\n",
    "            res = []\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alto_extract(altofile, to_path = ramdisk):\n",
    "    \"\"\"\n",
    "    Pakk ut tarfil til ramdisk og returnerer mappen filene ligger i\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    tf = tarfile.open(altofile, 'r')\n",
    "    # lag mappe på disk med navnet foran det som står foran .tar\n",
    "    filename = os.path.basename(altofile)\n",
    "    dname = filename.split('.tar')[0]\n",
    "    ndir = os.path.join(to_path, dname )\n",
    "    os.mkdir(ndir)\n",
    "    # Pakk ut alt til mappen\n",
    "    tf.extractall(ndir)\n",
    "    tf.close()\n",
    "    return ndir\n",
    "\n",
    "\n",
    "def extract_image_alto(ndir):\n",
    "    \"\"\"Hent ut alle bildene i alto-filen. Mappen ndir peker til mappen der tarfilene ligger\"\"\"\n",
    "    \n",
    "    import xml.etree.ElementTree as ET\n",
    "    import shutil\n",
    "    \n",
    "    ns = {'mix': \"http://www.loc.gov/mix/\"} \n",
    "    # XML-filene ligger i mappen ndir, så gå gjennom med os.walk()\n",
    "    # Alle filene blir liggende i variabelen f\n",
    "    \n",
    "    r,d,f = next(os.walk(ndir))\n",
    "    \n",
    "    # hent sidene i teksten og legg dem i variabelen pages\n",
    "    # skip metadatafilene - tekstene har sidenummer representert som 4-sifrede nummer, f.eks. 0014\n",
    "    # for bøker ligger de i slutten på _-sekvensen, for aviser er de nest sist\n",
    "    \n",
    "    # hent oppløsningen fra metsfil\n",
    "    metsfile = [fmets for fmets in f if fmets.endswith('mets.xml')]\n",
    "    if metsfile != []:\n",
    "        metsfile = os.path.join(r, metsfile[0])\n",
    "        tree = ET.parse(metsfile)\n",
    "        root = tree.getroot()\n",
    "        resolutions = {element.text for element in root.findall(\".//mix:XphysScanResolution\", ns)}\n",
    "        resolution = list(resolutions)[0]\n",
    "    else:\n",
    "        resolution = 100 \n",
    "    \n",
    "    pages = []\n",
    "    \n",
    "    for page in f:\n",
    "        pag = page.split('.xml')[0].split('_')\n",
    "        try:\n",
    "            int(pag[2])\n",
    "            pages.append((page, int(pag[2])))\n",
    "            \n",
    "        except:\n",
    "            True\n",
    "    # print(pages)\n",
    "    # alle avsnitt blir nummerert fortløpende\n",
    "    \n",
    "    illustrations = []\n",
    "    # sorter variabelen pages på sidenummer, andre ledd i tuplet\n",
    "    for page in sorted(pages, key=lambda x: x[1]):\n",
    "        page_file = os.path.join(r, page[0])\n",
    "        page_num = page[1]\n",
    "        file_identifier = page[0].split('.')[0] # remove .xml\n",
    "        #print(page[0], page[1])\n",
    "        # parse XML-fila og få tak i rotelementet root\n",
    "        tree = ET.parse(page_file)\n",
    "        root = tree.getroot()\n",
    "        #print(root)\n",
    "        # Gå gjennom XML-strukturen via TextBlock, som er avsnittselementet\n",
    "        for paragraph in root.findall(\".//*[@TYPE='Illustration']\"):\n",
    "            illustrations.append(\n",
    "                {'page': file_identifier, \n",
    "                 'pagenum':page_num,\n",
    "                 'resolution': resolution,\n",
    "                 'hpos': paragraph.attrib[\"HPOS\"],\n",
    "                 'vpos':paragraph.attrib[\"VPOS\"],\n",
    "                 'width':paragraph.attrib[\"WIDTH\"],\n",
    "                 'height':paragraph.attrib[\"HEIGHT\"],\n",
    "                 'type': 'Illustration'\n",
    "                 }\n",
    "            )\n",
    "        for paragraph in root.findall(\".//*[@TYPE='GraphicalElement']\"):\n",
    "            illustrations.append(\n",
    "                {'page': file_identifier,\n",
    "                 'pagenum':page_num,\n",
    "                 'resolution': resolution,\n",
    "                 'hpos': paragraph.attrib[\"HPOS\"],\n",
    "                 'vpos':paragraph.attrib[\"VPOS\"],\n",
    "                 'width':paragraph.attrib[\"WIDTH\"],\n",
    "                 'height':paragraph.attrib[\"HEIGHT\"],\n",
    "                 'type': 'GraphicalElement'\n",
    "                 }\n",
    "            )\n",
    "        \n",
    "    return illustrations\n",
    "\n",
    "def clean_up_ramdisk():\n",
    "    import shutil\n",
    "    r,d,f = next(os.walk(ramdisk))\n",
    "    for folder in d:\n",
    "        shutil.rmtree(os.path.join(ramdisk, folder))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def fetch_words(altofile, to_path=ramdisk):\n",
    "    \"\"\"Lag en produksjonsløype for en enkelt ALTO-fil \"\"\"\n",
    "    \n",
    "    import shutil\n",
    "    \n",
    "    ndir = alto_extract(altofile, to_path=to_path)\n",
    "    print(ndir)\n",
    "    text = process_alto(ndir)\n",
    "    shutil.rmtree(ndir)\n",
    "    return text\n",
    "\n",
    "def process_tar(tarfile):\n",
    "    \"\"\" illustration_database is global variable - set it outside function\"\"\"\n",
    "    alto_dir = alto_extract(tarfile)\n",
    "    illustrations = extract_image_alto(alto_dir)\n",
    "    for i in illustrations:\n",
    "        query(GLOBAL_illustration_database, \n",
    "          \"insert into illustrations values (?,?,?,?,?,?,?,?)\", \n",
    "                (i['page'], \n",
    "                 i['pagenum'],\n",
    "                 i['resolution'],\n",
    "                 i['hpos'],\n",
    "                 i['vpos'],\n",
    "                 i['width'],\n",
    "                 i['height'],\n",
    "                 i['type'] ))\n",
    "    shutil.rmtree(alto_dir)\n",
    "    \n",
    "def process_tar_directory(tarfiles_dir):\n",
    "    \"\"\" illustration_database is global variable - set it outside function\"\"\"\n",
    "    safe = \"\".join([c for c in tarfiles_dir if c.isalpha() or c.isdigit() or c==' ']).rstrip()\n",
    "    illustration_database = \"illustrations_\" + safe + \".db\"\n",
    "    query(illustration_database, \"\"\"create table illustrations (\n",
    "        page varchar, \n",
    "         pagenum int,\n",
    "         resolution int,\n",
    "         hpos int,\n",
    "         vpos int,\n",
    "         width int,\n",
    "         height int,\n",
    "         type varchar)\"\"\")\n",
    "    print(tarfiles_dir, illustration_database)\n",
    "    r, d, f = next(os.walk(tarfiles_dir))\n",
    "    count = 0\n",
    "    for file in f:\n",
    "        count += 1\n",
    "        tarfile = os.path.join(r, file)\n",
    "        alto_dir = alto_extract(tarfile)\n",
    "        illustrations = extract_image_alto(alto_dir)\n",
    "        for i in illustrations:\n",
    "            query(illustration_database, \n",
    "              \"insert into illustrations values (?,?,?,?,?,?,?,?)\", \n",
    "                    (i['page'], \n",
    "                     i['pagenum'],\n",
    "                     i['resolution'],\n",
    "                     i['hpos'],\n",
    "                     i['vpos'],\n",
    "                     i['width'],\n",
    "                     i['height'],\n",
    "                     i['type'] ))\n",
    "        shutil.rmtree(alto_dir)\n",
    "        if count % 10000 == 0:\n",
    "            print(i, tarfile)\n",
    "    return True\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sqlite3 database for illustrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "illustrationdb = 'illustrations_bookshelf_spb.db'\n",
    "query(illustrationdb, \"\"\"create table illustrations (\n",
    "        page varchar, \n",
    "         pagenum int,\n",
    "         resolution int,\n",
    "         hpos int,\n",
    "         vpos int,\n",
    "         width int,\n",
    "         height int,\n",
    "         type varchar)\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOBAL_illustration_database = illustrationdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query(GLOBAL_illustration_database, \"drop table illustrations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill up database with files, use parallell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r,d,f = next(os.walk('/disk4/1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_up_ramdisk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_tar_t(tf):\n",
    "    t = time()\n",
    "    process_tar(tf)\n",
    "    print(tf, time() - t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallell (so serial is approx 2.1 sec pr. file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.Pool at 0x7f059c6dea20>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kjør hovedloop for å fylle opp database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk4/3 illustrations_disk43.db\n",
      "/disk4/2 illustrations_disk42.db\n",
      "/disk4/1 illustrations_disk41.db\n",
      "/disk4/6 illustrations_disk46.db\n",
      "/disk4/4 illustrations_disk44.db\n",
      "/disk4/5 illustrations_disk45.db\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    worker = Pool(7)\n",
    "    directories = [os.path.join('/disk4', str(i)) for i in range(1, 7)]\n",
    "    worker.map(process_tar_directory, directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
